{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for regenerated plots used on thesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO : \n",
    "    1. Add map \n",
    "    2. Heatmap Missing Values (done)\n",
    "    3. Subplot of filters\n",
    "    4. Countour plot of a temporally averaged data. Use one month now to generate the plot -- > update later for all entire timeperiod. \n",
    "    5. FIX Missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map over domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i 'plot_map_domain.py' # use tensoflow enviornment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing values Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning.. Using pgf backend, no GUI available. use plt.savefig() for inpection\n",
      "year: 2004, month: 1\n",
      "year: 2004, month: 2\n",
      "year: 2004, month: 3\n",
      "year: 2007, month: 11\n",
      "year: 2007, month: 12\n",
      "year: 2008, month: 1\n",
      "year: 2008, month: 2\n",
      "year: 2008, month: 3\n",
      "year: 2008, month: 4\n",
      "year: 2008, month: 5\n",
      "year: 2008, month: 6\n",
      "year: 2008, month: 7\n",
      "year: 2008, month: 8\n",
      "year: 2008, month: 9\n",
      "year: 2008, month: 10\n",
      "year: 2008, month: 11\n",
      "year: 2008, month: 12\n",
      "year: 2009, month: 1\n",
      "year: 2009, month: 2\n",
      "year: 2009, month: 3\n",
      "year: 2009, month: 4\n",
      "year: 2009, month: 5\n",
      "year: 2009, month: 6\n",
      "year: 2009, month: 7\n",
      "year: 2009, month: 8\n",
      "year: 2009, month: 9\n",
      "year: 2009, month: 10\n",
      "year: 2009, month: 11\n",
      "year: 2009, month: 12\n",
      "year: 2010, month: 1\n",
      "year: 2010, month: 2\n",
      "year: 2010, month: 3\n",
      "year: 2010, month: 4\n",
      "year: 2010, month: 5\n",
      "year: 2010, month: 6\n",
      "year: 2010, month: 7\n",
      "year: 2010, month: 8\n",
      "year: 2010, month: 9\n",
      "year: 2010, month: 10\n",
      "year: 2010, month: 11\n",
      "year: 2010, month: 12\n",
      "year: 2011, month: 1\n",
      "year: 2011, month: 2\n",
      "year: 2011, month: 3\n",
      "year: 2011, month: 4\n",
      "year: 2011, month: 5\n",
      "year: 2011, month: 6\n",
      "year: 2011, month: 7\n",
      "year: 2011, month: 8\n",
      "year: 2011, month: 9\n",
      "year: 2011, month: 10\n",
      "year: 2011, month: 11\n",
      "year: 2011, month: 12\n",
      "year: 2012, month: 1\n",
      "year: 2012, month: 2\n",
      "year: 2012, month: 3\n",
      "year: 2012, month: 4\n",
      "year: 2012, month: 5\n",
      "year: 2012, month: 6\n",
      "year: 2012, month: 7\n",
      "year: 2012, month: 8\n",
      "year: 2012, month: 9\n",
      "year: 2012, month: 10\n",
      "year: 2012, month: 11\n",
      "year: 2012, month: 12\n",
      "year: 2013, month: 1\n",
      "year: 2013, month: 2\n",
      "year: 2013, month: 3\n",
      "year: 2013, month: 4\n",
      "year: 2013, month: 5\n",
      "year: 2013, month: 6\n",
      "year: 2013, month: 7\n",
      "year: 2013, month: 8\n",
      "year: 2013, month: 9\n",
      "year: 2013, month: 10\n",
      "year: 2013, month: 11\n",
      "year: 2013, month: 12\n",
      "year: 2014, month: 1\n",
      "year: 2014, month: 2\n",
      "year: 2014, month: 3\n",
      "year: 2014, month: 4\n",
      "year: 2014, month: 5\n",
      "year: 2014, month: 6\n",
      "year: 2014, month: 7\n",
      "year: 2014, month: 8\n",
      "year: 2014, month: 9\n",
      "year: 2014, month: 10\n",
      "year: 2014, month: 11\n",
      "year: 2014, month: 12\n",
      "year: 2015, month: 1\n",
      "year: 2015, month: 2\n",
      "year: 2015, month: 3\n",
      "year: 2015, month: 4\n",
      "year: 2015, month: 5\n",
      "year: 2015, month: 6\n",
      "year: 2015, month: 7\n",
      "year: 2015, month: 8\n",
      "year: 2015, month: 9\n",
      "year: 2015, month: 10\n",
      "year: 2015, month: 11\n",
      "year: 2015, month: 12\n",
      "year: 2016, month: 1\n",
      "year: 2016, month: 2\n",
      "year: 2016, month: 3\n",
      "year: 2016, month: 4\n",
      "year: 2016, month: 5\n",
      "year: 2016, month: 6\n",
      "year: 2016, month: 7\n",
      "year: 2016, month: 8\n",
      "year: 2016, month: 9\n",
      "year: 2016, month: 10\n",
      "year: 2016, month: 11\n",
      "year: 2016, month: 12\n",
      "year: 2017, month: 1\n",
      "year: 2017, month: 2\n",
      "year: 2017, month: 3\n",
      "year: 2017, month: 4\n",
      "year: 2017, month: 5\n",
      "year: 2017, month: 6\n",
      "year: 2017, month: 7\n",
      "year: 2017, month: 8\n",
      "year: 2017, month: 9\n",
      "year: 2017, month: 10\n",
      "year: 2017, month: 11\n",
      "year: 2017, month: 12\n",
      "year: 2018, month: 1\n",
      "year: 2018, month: 2\n",
      "year: 2018, month: 3\n",
      "year: 2018, month: 4\n",
      "year: 2018, month: 5\n",
      "year: 2018, month: 6\n",
      "year: 2018, month: 7\n",
      "year: 2018, month: 8\n",
      "year: 2018, month: 9\n",
      "year: 2018, month: 10\n",
      "year: 2018, month: 11\n",
      "year: 2018, month: 12\n"
     ]
    }
   ],
   "source": [
    "%run -i 'plot_heatmap_missing_values.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suplot filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning.. Using pgf backend, no GUI available. use plt.savefig() for inpection\n"
     ]
    }
   ],
   "source": [
    "%run -i 'plot_filters.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot example artefact "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning.. Using pgf backend, no GUI available. use plt.savefig() for inpection\n"
     ]
    }
   ],
   "source": [
    "%run -i 'plot_example_artefact.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subplot all variables : Contour plot temporally averaged "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning.. Using pgf backend, no GUI available. use plt.savefig() for inpection\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Not five of each files, missing variables in file list!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/MS/sclouds/plot/plot_temporally_averaged_grid_all_variables.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mn_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_xarray_dataset_for_period\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'2012-01-01'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'2012-01-31'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/MS/sclouds/io/utils.py\u001b[0m in \u001b[0;36mget_xarray_dataset_for_period\u001b[0;34m(start, stop)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \"\"\"\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m#from utils import merge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_list_of_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Num files {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/MS/sclouds/io/utils.py\u001b[0m in \u001b[0;36mget_list_of_files\u001b[0;34m(start, stop)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0msubset\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0msmaller\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msmaller\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mmin_fil\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# results in all the files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Not five of each files, missing variables in file list!\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"No files found, check if you have mounted lagringshotellet.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Not five of each files, missing variables in file list!"
     ]
    }
   ],
   "source": [
    "%run -i 'plot_temporally_averaged_grid_all_variables.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monthly spatially averages subplot of all values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning this duplicates the RH in plot for tcc\n",
      "Warning this duplicates the RH in plot for tcc\n",
      "Warning this duplicates the RH in plot for tcc\n",
      "Warning this duplicates the RH in plot for tcc\n"
     ]
    }
   ],
   "source": [
    "%run -i 'plot_monthly_means.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equivalent of monthly mean plot for the first week of every month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num files 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hanna/MS/sclouds/helpers.py:81: FutureWarning: In xarray version 0.15 the default behaviour of `open_mfdataset`\n",
      "will change. To retain the existing behavior, pass\n",
      "combine='nested'. To use future default behavior, pass\n",
      "combine='by_coords'. See\n",
      "http://xarray.pydata.org/en/stable/combining.html#combining-multi\n",
      "\n",
      "  return xr.open_mfdataset(files, compat='no_conflicts', join='outer')\n",
      "/home/hanna/anaconda3/envs/final/lib/python3.7/site-packages/xarray/backends/api.py:941: FutureWarning: The datasets supplied have global dimension coordinates. You may want\n",
      "to use the new `combine_by_coords` function (or the\n",
      "`combine='by_coords'` option to `open_mfdataset`) to order the datasets\n",
      "before concatenation. Alternatively, to continue concatenating based\n",
      "on the order the datasets are supplied in future, please use the new\n",
      "`combine_nested` function (or the `combine='nested'` option to\n",
      "open_mfdataset).The datasets supplied require both concatenation and merging. From\n",
      "xarray version 0.15 this will operation will require either using the\n",
      "new `combine_nested` function (or the `combine='nested'` option to\n",
      "open_mfdataset), with a nested list structure such that you can combine\n",
      "along the dimensions None. Alternatively if your datasets have global\n",
      "dimension coordinates then you can use the new `combine_by_coords`\n",
      "function.\n",
      "  from_openmfds=True,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num files 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hanna/MS/sclouds/helpers.py:81: FutureWarning: In xarray version 0.15 the default behaviour of `open_mfdataset`\n",
      "will change. To retain the existing behavior, pass\n",
      "combine='nested'. To use future default behavior, pass\n",
      "combine='by_coords'. See\n",
      "http://xarray.pydata.org/en/stable/combining.html#combining-multi\n",
      "\n",
      "  return xr.open_mfdataset(files, compat='no_conflicts', join='outer')\n",
      "/home/hanna/anaconda3/envs/final/lib/python3.7/site-packages/xarray/backends/api.py:941: FutureWarning: The datasets supplied have global dimension coordinates. You may want\n",
      "to use the new `combine_by_coords` function (or the\n",
      "`combine='by_coords'` option to `open_mfdataset`) to order the datasets\n",
      "before concatenation. Alternatively, to continue concatenating based\n",
      "on the order the datasets are supplied in future, please use the new\n",
      "`combine_nested` function (or the `combine='nested'` option to\n",
      "open_mfdataset).The datasets supplied require both concatenation and merging. From\n",
      "xarray version 0.15 this will operation will require either using the\n",
      "new `combine_nested` function (or the `combine='nested'` option to\n",
      "open_mfdataset), with a nested list structure such that you can combine\n",
      "along the dimensions None. Alternatively if your datasets have global\n",
      "dimension coordinates then you can use the new `combine_by_coords`\n",
      "function.\n",
      "  from_openmfds=True,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num files 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hanna/MS/sclouds/helpers.py:81: FutureWarning: In xarray version 0.15 the default behaviour of `open_mfdataset`\n",
      "will change. To retain the existing behavior, pass\n",
      "combine='nested'. To use future default behavior, pass\n",
      "combine='by_coords'. See\n",
      "http://xarray.pydata.org/en/stable/combining.html#combining-multi\n",
      "\n",
      "  return xr.open_mfdataset(files, compat='no_conflicts', join='outer')\n",
      "/home/hanna/anaconda3/envs/final/lib/python3.7/site-packages/xarray/backends/api.py:941: FutureWarning: The datasets supplied have global dimension coordinates. You may want\n",
      "to use the new `combine_by_coords` function (or the\n",
      "`combine='by_coords'` option to `open_mfdataset`) to order the datasets\n",
      "before concatenation. Alternatively, to continue concatenating based\n",
      "on the order the datasets are supplied in future, please use the new\n",
      "`combine_nested` function (or the `combine='nested'` option to\n",
      "open_mfdataset).The datasets supplied require both concatenation and merging. From\n",
      "xarray version 0.15 this will operation will require either using the\n",
      "new `combine_nested` function (or the `combine='nested'` option to\n",
      "open_mfdataset), with a nested list structure such that you can combine\n",
      "along the dimensions None. Alternatively if your datasets have global\n",
      "dimension coordinates then you can use the new `combine_by_coords`\n",
      "function.\n",
      "  from_openmfds=True,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num files 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hanna/MS/sclouds/helpers.py:81: FutureWarning: In xarray version 0.15 the default behaviour of `open_mfdataset`\n",
      "will change. To retain the existing behavior, pass\n",
      "combine='nested'. To use future default behavior, pass\n",
      "combine='by_coords'. See\n",
      "http://xarray.pydata.org/en/stable/combining.html#combining-multi\n",
      "\n",
      "  return xr.open_mfdataset(files, compat='no_conflicts', join='outer')\n",
      "/home/hanna/anaconda3/envs/final/lib/python3.7/site-packages/xarray/backends/api.py:941: FutureWarning: The datasets supplied have global dimension coordinates. You may want\n",
      "to use the new `combine_by_coords` function (or the\n",
      "`combine='by_coords'` option to `open_mfdataset`) to order the datasets\n",
      "before concatenation. Alternatively, to continue concatenating based\n",
      "on the order the datasets are supplied in future, please use the new\n",
      "`combine_nested` function (or the `combine='nested'` option to\n",
      "open_mfdataset).The datasets supplied require both concatenation and merging. From\n",
      "xarray version 0.15 this will operation will require either using the\n",
      "new `combine_nested` function (or the `combine='nested'` option to\n",
      "open_mfdataset), with a nested list structure such that you can combine\n",
      "along the dimensions None. Alternatively if your datasets have global\n",
      "dimension coordinates then you can use the new `combine_by_coords`\n",
      "function.\n",
      "  from_openmfds=True,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num files 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hanna/MS/sclouds/helpers.py:81: FutureWarning: In xarray version 0.15 the default behaviour of `open_mfdataset`\n",
      "will change. To retain the existing behavior, pass\n",
      "combine='nested'. To use future default behavior, pass\n",
      "combine='by_coords'. See\n",
      "http://xarray.pydata.org/en/stable/combining.html#combining-multi\n",
      "\n",
      "  return xr.open_mfdataset(files, compat='no_conflicts', join='outer')\n",
      "/home/hanna/anaconda3/envs/final/lib/python3.7/site-packages/xarray/backends/api.py:941: FutureWarning: The datasets supplied have global dimension coordinates. You may want\n",
      "to use the new `combine_by_coords` function (or the\n",
      "`combine='by_coords'` option to `open_mfdataset`) to order the datasets\n",
      "before concatenation. Alternatively, to continue concatenating based\n",
      "on the order the datasets are supplied in future, please use the new\n",
      "`combine_nested` function (or the `combine='nested'` option to\n",
      "open_mfdataset).The datasets supplied require both concatenation and merging. From\n",
      "xarray version 0.15 this will operation will require either using the\n",
      "new `combine_nested` function (or the `combine='nested'` option to\n",
      "open_mfdataset), with a nested list structure such that you can combine\n",
      "along the dimensions None. Alternatively if your datasets have global\n",
      "dimension coordinates then you can use the new `combine_by_coords`\n",
      "function.\n",
      "  from_openmfds=True,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num files 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hanna/MS/sclouds/helpers.py:81: FutureWarning: In xarray version 0.15 the default behaviour of `open_mfdataset`\n",
      "will change. To retain the existing behavior, pass\n",
      "combine='nested'. To use future default behavior, pass\n",
      "combine='by_coords'. See\n",
      "http://xarray.pydata.org/en/stable/combining.html#combining-multi\n",
      "\n",
      "  return xr.open_mfdataset(files, compat='no_conflicts', join='outer')\n",
      "/home/hanna/anaconda3/envs/final/lib/python3.7/site-packages/xarray/backends/api.py:941: FutureWarning: The datasets supplied have global dimension coordinates. You may want\n",
      "to use the new `combine_by_coords` function (or the\n",
      "`combine='by_coords'` option to `open_mfdataset`) to order the datasets\n",
      "before concatenation. Alternatively, to continue concatenating based\n",
      "on the order the datasets are supplied in future, please use the new\n",
      "`combine_nested` function (or the `combine='nested'` option to\n",
      "open_mfdataset).The datasets supplied require both concatenation and merging. From\n",
      "xarray version 0.15 this will operation will require either using the\n",
      "new `combine_nested` function (or the `combine='nested'` option to\n",
      "open_mfdataset), with a nested list structure such that you can combine\n",
      "along the dimensions None. Alternatively if your datasets have global\n",
      "dimension coordinates then you can use the new `combine_by_coords`\n",
      "function.\n",
      "  from_openmfds=True,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num files 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hanna/MS/sclouds/helpers.py:81: FutureWarning: In xarray version 0.15 the default behaviour of `open_mfdataset`\n",
      "will change. To retain the existing behavior, pass\n",
      "combine='nested'. To use future default behavior, pass\n",
      "combine='by_coords'. See\n",
      "http://xarray.pydata.org/en/stable/combining.html#combining-multi\n",
      "\n",
      "  return xr.open_mfdataset(files, compat='no_conflicts', join='outer')\n",
      "/home/hanna/anaconda3/envs/final/lib/python3.7/site-packages/xarray/backends/api.py:941: FutureWarning: The datasets supplied have global dimension coordinates. You may want\n",
      "to use the new `combine_by_coords` function (or the\n",
      "`combine='by_coords'` option to `open_mfdataset`) to order the datasets\n",
      "before concatenation. Alternatively, to continue concatenating based\n",
      "on the order the datasets are supplied in future, please use the new\n",
      "`combine_nested` function (or the `combine='nested'` option to\n",
      "open_mfdataset).The datasets supplied require both concatenation and merging. From\n",
      "xarray version 0.15 this will operation will require either using the\n",
      "new `combine_nested` function (or the `combine='nested'` option to\n",
      "open_mfdataset), with a nested list structure such that you can combine\n",
      "along the dimensions None. Alternatively if your datasets have global\n",
      "dimension coordinates then you can use the new `combine_by_coords`\n",
      "function.\n",
      "  from_openmfds=True,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num files 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hanna/MS/sclouds/helpers.py:81: FutureWarning: In xarray version 0.15 the default behaviour of `open_mfdataset`\n",
      "will change. To retain the existing behavior, pass\n",
      "combine='nested'. To use future default behavior, pass\n",
      "combine='by_coords'. See\n",
      "http://xarray.pydata.org/en/stable/combining.html#combining-multi\n",
      "\n",
      "  return xr.open_mfdataset(files, compat='no_conflicts', join='outer')\n",
      "/home/hanna/anaconda3/envs/final/lib/python3.7/site-packages/xarray/backends/api.py:941: FutureWarning: The datasets supplied have global dimension coordinates. You may want\n",
      "to use the new `combine_by_coords` function (or the\n",
      "`combine='by_coords'` option to `open_mfdataset`) to order the datasets\n",
      "before concatenation. Alternatively, to continue concatenating based\n",
      "on the order the datasets are supplied in future, please use the new\n",
      "`combine_nested` function (or the `combine='nested'` option to\n",
      "open_mfdataset).The datasets supplied require both concatenation and merging. From\n",
      "xarray version 0.15 this will operation will require either using the\n",
      "new `combine_nested` function (or the `combine='nested'` option to\n",
      "open_mfdataset), with a nested list structure such that you can combine\n",
      "along the dimensions None. Alternatively if your datasets have global\n",
      "dimension coordinates then you can use the new `combine_by_coords`\n",
      "function.\n",
      "  from_openmfds=True,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num files 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hanna/MS/sclouds/helpers.py:81: FutureWarning: In xarray version 0.15 the default behaviour of `open_mfdataset`\n",
      "will change. To retain the existing behavior, pass\n",
      "combine='nested'. To use future default behavior, pass\n",
      "combine='by_coords'. See\n",
      "http://xarray.pydata.org/en/stable/combining.html#combining-multi\n",
      "\n",
      "  return xr.open_mfdataset(files, compat='no_conflicts', join='outer')\n",
      "/home/hanna/anaconda3/envs/final/lib/python3.7/site-packages/xarray/backends/api.py:941: FutureWarning: The datasets supplied have global dimension coordinates. You may want\n",
      "to use the new `combine_by_coords` function (or the\n",
      "`combine='by_coords'` option to `open_mfdataset`) to order the datasets\n",
      "before concatenation. Alternatively, to continue concatenating based\n",
      "on the order the datasets are supplied in future, please use the new\n",
      "`combine_nested` function (or the `combine='nested'` option to\n",
      "open_mfdataset).The datasets supplied require both concatenation and merging. From\n",
      "xarray version 0.15 this will operation will require either using the\n",
      "new `combine_nested` function (or the `combine='nested'` option to\n",
      "open_mfdataset), with a nested list structure such that you can combine\n",
      "along the dimensions None. Alternatively if your datasets have global\n",
      "dimension coordinates then you can use the new `combine_by_coords`\n",
      "function.\n",
      "  from_openmfds=True,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num files 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hanna/MS/sclouds/helpers.py:81: FutureWarning: In xarray version 0.15 the default behaviour of `open_mfdataset`\n",
      "will change. To retain the existing behavior, pass\n",
      "combine='nested'. To use future default behavior, pass\n",
      "combine='by_coords'. See\n",
      "http://xarray.pydata.org/en/stable/combining.html#combining-multi\n",
      "\n",
      "  return xr.open_mfdataset(files, compat='no_conflicts', join='outer')\n",
      "/home/hanna/anaconda3/envs/final/lib/python3.7/site-packages/xarray/backends/api.py:941: FutureWarning: The datasets supplied have global dimension coordinates. You may want\n",
      "to use the new `combine_by_coords` function (or the\n",
      "`combine='by_coords'` option to `open_mfdataset`) to order the datasets\n",
      "before concatenation. Alternatively, to continue concatenating based\n",
      "on the order the datasets are supplied in future, please use the new\n",
      "`combine_nested` function (or the `combine='nested'` option to\n",
      "open_mfdataset).The datasets supplied require both concatenation and merging. From\n",
      "xarray version 0.15 this will operation will require either using the\n",
      "new `combine_nested` function (or the `combine='nested'` option to\n",
      "open_mfdataset), with a nested list structure such that you can combine\n",
      "along the dimensions None. Alternatively if your datasets have global\n",
      "dimension coordinates then you can use the new `combine_by_coords`\n",
      "function.\n",
      "  from_openmfds=True,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num files 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hanna/MS/sclouds/helpers.py:81: FutureWarning: In xarray version 0.15 the default behaviour of `open_mfdataset`\n",
      "will change. To retain the existing behavior, pass\n",
      "combine='nested'. To use future default behavior, pass\n",
      "combine='by_coords'. See\n",
      "http://xarray.pydata.org/en/stable/combining.html#combining-multi\n",
      "\n",
      "  return xr.open_mfdataset(files, compat='no_conflicts', join='outer')\n",
      "/home/hanna/anaconda3/envs/final/lib/python3.7/site-packages/xarray/backends/api.py:941: FutureWarning: The datasets supplied have global dimension coordinates. You may want\n",
      "to use the new `combine_by_coords` function (or the\n",
      "`combine='by_coords'` option to `open_mfdataset`) to order the datasets\n",
      "before concatenation. Alternatively, to continue concatenating based\n",
      "on the order the datasets are supplied in future, please use the new\n",
      "`combine_nested` function (or the `combine='nested'` option to\n",
      "open_mfdataset).The datasets supplied require both concatenation and merging. From\n",
      "xarray version 0.15 this will operation will require either using the\n",
      "new `combine_nested` function (or the `combine='nested'` option to\n",
      "open_mfdataset), with a nested list structure such that you can combine\n",
      "along the dimensions None. Alternatively if your datasets have global\n",
      "dimension coordinates then you can use the new `combine_by_coords`\n",
      "function.\n",
      "  from_openmfds=True,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num files 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hanna/MS/sclouds/helpers.py:81: FutureWarning: In xarray version 0.15 the default behaviour of `open_mfdataset`\n",
      "will change. To retain the existing behavior, pass\n",
      "combine='nested'. To use future default behavior, pass\n",
      "combine='by_coords'. See\n",
      "http://xarray.pydata.org/en/stable/combining.html#combining-multi\n",
      "\n",
      "  return xr.open_mfdataset(files, compat='no_conflicts', join='outer')\n",
      "/home/hanna/anaconda3/envs/final/lib/python3.7/site-packages/xarray/backends/api.py:941: FutureWarning: The datasets supplied have global dimension coordinates. You may want\n",
      "to use the new `combine_by_coords` function (or the\n",
      "`combine='by_coords'` option to `open_mfdataset`) to order the datasets\n",
      "before concatenation. Alternatively, to continue concatenating based\n",
      "on the order the datasets are supplied in future, please use the new\n",
      "`combine_nested` function (or the `combine='nested'` option to\n",
      "open_mfdataset).The datasets supplied require both concatenation and merging. From\n",
      "xarray version 0.15 this will operation will require either using the\n",
      "new `combine_nested` function (or the `combine='nested'` option to\n",
      "open_mfdataset), with a nested list structure such that you can combine\n",
      "along the dimensions None. Alternatively if your datasets have global\n",
      "dimension coordinates then you can use the new `combine_by_coords`\n",
      "function.\n",
      "  from_openmfds=True,\n"
     ]
    }
   ],
   "source": [
    "%run -i 'plot_one_week_of_spatially_averaged_values.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bar plot global statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i 'plot_global_statistics_for_several_filters.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Countourplot all statistics \n",
    "## Need to update this path when the data is done working on wessel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i 'plot_countourplot_one_statistics_all_variables.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot correlation maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i 'plot_correlation_maps.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot model results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot signal from Artefact "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i 'plot_signal_artefact.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
