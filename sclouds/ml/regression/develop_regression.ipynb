{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "write_path = '/uio/lagringshotell/geofag/students/metos/hannasv/ERA5_monthly/'\n",
    "read_path = '/uio/lagringshotell/geofag/students/metos/hannasv/dataERA5_grib/'\n",
    "\n",
    "base = '/uio/lagringshotell/geofag/students/metos/hannasv/'\n",
    "base = '/home/hanna/lagrings'\n",
    "#read_path = '/uio/lagringshotell/geofag/students/metos/hannasv/dataERA5_grib/'\n",
    "read_folder = 'ERA5_monthly'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = os.path.join(base, read_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/hanna/lagrings/ERA5_monthly'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "895"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = glob.glob(os.path.join(folder, '*.nc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# files = glob.glob(os.path.join(read_path, '*.grib'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:        (latitude: 81, longitude: 161, time: 61368)\n",
       "Coordinates:\n",
       "    number         int64 ...\n",
       "  * time           (time) datetime64[ns] 2012-01-01 ... 2018-12-31T23:00:00\n",
       "    step           timedelta64[ns] ...\n",
       "    isobaricInhPa  int64 ...\n",
       "  * latitude       (latitude) float64 50.0 49.75 49.5 49.25 ... 30.5 30.25 30.0\n",
       "  * longitude      (longitude) float64 -15.0 -14.75 -14.5 ... 24.5 24.75 25.0\n",
       "    valid_time     (time) datetime64[ns] ...\n",
       "Data variables:\n",
       "    q              (time, latitude, longitude) float32 ...\n",
       "Attributes:\n",
       "    GRIB_edition:            1\n",
       "    GRIB_centre:             ecmf\n",
       "    GRIB_centreDescription:  European Centre for Medium-Range Weather Forecasts\n",
       "    GRIB_subCentre:          0\n",
       "    Conventions:             CF-1.7\n",
       "    institution:             European Centre for Medium-Range Weather Forecasts\n",
       "    history:                 2020-02-20T09:59:12 GRIB to CDM+CF via cfgrib-0...."
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = xr.open_dataset(files[6], engine = 'cfgrib')\n",
    "domain = data.sel(latitude = slice(50,30), longitude = slice(-15, 25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_to_numpy(pixel, bias = True):\n",
    "    \"\"\" Dataset. \"\"\" \n",
    "    n = len(pixel.time.values)\n",
    "    \n",
    "    if bias:\n",
    "        num_vars = 4+1\n",
    "    X = np.zeros((n, num_vars))\n",
    "    \n",
    "    q   = pixel.q.values\n",
    "    t2m   = pixel.t2m.values\n",
    "    r   = pixel.r.values\n",
    "    sp  = pixel.sp.values\n",
    "    tcc = pixel.tcc.values\n",
    "        \n",
    "    X[:, 0] = q\n",
    "    X[:, 1] = t2m\n",
    "    X[:, 2] = r\n",
    "    X[:, 3] = sp\n",
    "    X[4, :] = 1\n",
    "    return X, tcc[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:        (latitude: 81, longitude: 161, time: 70128)\n",
       "Coordinates:\n",
       "    number         int64 ...\n",
       "  * time           (time) datetime64[ns] 2004-01-01 ... 2011-12-31T23:00:00\n",
       "    step           timedelta64[ns] ...\n",
       "    isobaricInhPa  int64 ...\n",
       "  * latitude       (latitude) float64 50.0 49.75 49.5 49.25 ... 30.5 30.25 30.0\n",
       "  * longitude      (longitude) float64 -15.0 -14.75 -14.5 ... 24.5 24.75 25.0\n",
       "    valid_time     (time) datetime64[ns] ...\n",
       "Data variables:\n",
       "    r              (time, latitude, longitude) float32 ...\n",
       "Attributes:\n",
       "    GRIB_edition:            1\n",
       "    GRIB_centre:             ecmf\n",
       "    GRIB_centreDescription:  European Centre for Medium-Range Weather Forecasts\n",
       "    GRIB_subCentre:          0\n",
       "    Conventions:             CF-1.7\n",
       "    institution:             European Centre for Medium-Range Weather Forecasts\n",
       "    history:                 2020-02-20T19:31:32 GRIB to CDM+CF via cfgrib-0...."
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = 'r'\n",
    "months = np.arange(1, 13)\n",
    "#years = np.arange(2012, 2019)\n",
    "years=np.arange(2004, 2012)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in months:\n",
    "    for y in years:\n",
    "        subset = domain.sel(time = '{}-{:02d}'.format(y, m))\n",
    "        filename = '{}_{:02d}_{}.nc'.format(y, m, var)\n",
    "        eng = 'netcdf4'\n",
    "        encoding_dict = {'{}'.format(var): {'zlib': True, 'complevel': 9}}\n",
    "        subset.to_netcdf(os.path.join(write_path, filename), encoding=encoding_dict, engine = eng)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deal with missing values\n",
    "## Merge datasets and only keep the times present in both "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy \n",
    "\n",
    "write_path = '/uio/lagringshotell/geofag/students/metos/hannasv/ERA5_monthly/'\n",
    "read_path = '/uio/lagringshotell/geofag/students/metos/hannasv/dataERA5_grib/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = '/uio/lagringshotell/geofag/students/metos/hannasv/results/ar/models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/uio/lagringshotell/geofag/students/metos/hannasv/ERA5_monthly/2012_05_q.nc',\n",
       " '/uio/lagringshotell/geofag/students/metos/hannasv/ERA5_monthly/2012_05_r.nc',\n",
       " '/uio/lagringshotell/geofag/students/metos/hannasv/ERA5_monthly/2012_05_t2m.nc',\n",
       " '/uio/lagringshotell/geofag/students/metos/hannasv/ERA5_monthly/2012_05_sp.nc',\n",
       " '/uio/lagringshotell/geofag/students/metos/hannasv/ERA5_monthly/2012_05_tcc.nc']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_to_numpy(pixel, bias = True):\n",
    "    \"\"\" Dataset. \"\"\" \n",
    "    n = len(pixel.time.values)\n",
    "    \n",
    "    if bias:\n",
    "        num_vars = 4+1\n",
    "    X = np.zeros((n, num_vars))\n",
    "    \n",
    "    q   = pixel.q.values\n",
    "    t2m   = pixel.t2m.values\n",
    "    r   = pixel.r.values\n",
    "    sp  = pixel.sp.values\n",
    "    tcc = pixel.tcc.values\n",
    "    \n",
    "    \n",
    "    X[:, 0] = q\n",
    "    X[:, 1] = t2m\n",
    "    X[:, 2] = r\n",
    "    X[:, 3] = sp\n",
    "    X[4, :] = 1\n",
    "    return X, tcc[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store R2, MSE, Weights, \n",
    "# Names Wt2m, Wr, Wq, Wsp, W1, W2, .... Wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(os.path.join(write_path, '2012_05_*.nc'))\n",
    "data = [xr.open_dataset(fil) for fil in files]\n",
    "most = xr.merge(data, 'equals')\n",
    "res = np.zeros((n_lat, n_lon, len(coeffs)))\n",
    "latitudes = most.latitude.values\n",
    "longitudes = most.longitude.values\n",
    "    \n",
    "n_lat = 81\n",
    "n_lon = 161\n",
    "\n",
    "for i, lat in enumerate(latitudes): # 81\n",
    "    for j, lon in enumerate(longitudes): # 161\n",
    "\n",
    "        pixel = most.sel(latitude = lat, longitude = lon)\n",
    "        X, y = dataset_to_numpy(pixel)\n",
    "        coeffs = np.dot(inv(np.dot(X.T, X)), np.dot(X.T, y))\n",
    "        res[i, j, :] =  coeffs.flatten()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Merge the two dictionaries and make a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_dict = {}\n",
    "order = 3\n",
    "\n",
    "for i in range(order):\n",
    "    var = 'W{}'.format(i+1)\n",
    "    temp_dict[var] = (['latitude', 'longitude'], np.zeros((n_lat, n_lon)))\n",
    "    \n",
    "vars_dict = {'b': (['latitude', 'longitude'], res[:, :, 4]),\n",
    "             'Wt2m':(['latitude', 'longitude'], res[:, :, 1]),\n",
    "             'Wr': (['latitude', 'longitude'], res[:, :, 2]),\n",
    "             'Wq':(['latitude', 'longitude'], res[:, :, 0]),\n",
    "             'Wsp': (['latitude', 'longitude'], res[:, :, 3]),\n",
    "              }\n",
    "temp_dict.update(vars_dict)\n",
    "ds = xr.Dataset(temp_dict,\n",
    "                 coords={'longitude': (['longitude'], longitudes),\n",
    "                         'latitude': (['latitude'], latitudes),\n",
    "                        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:    (latitude: 81, longitude: 161)\n",
       "Coordinates:\n",
       "  * latitude   (latitude) float64 30.0 30.25 30.5 30.75 ... 49.5 49.75 50.0\n",
       "  * longitude  (longitude) float64 -15.0 -14.75 -14.5 -14.25 ... 24.5 24.75 25.0\n",
       "Data variables:\n",
       "    b          (latitude, longitude) float64 -44.97 -49.1 -104.5 ... 56.62 51.73\n",
       "    Wq         (latitude, longitude) float64 45.4 49.76 105.4 ... -55.65 -50.77\n",
       "    Wt2m       (latitude, longitude) float64 -0.1195 -0.1336 ... 0.02458 0.02495\n",
       "    Wsp        (latitude, longitude) float64 0.0003534 0.0003937 ... -6.835e-05\n",
       "    W3         (latitude, longitude) float64 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0\n",
       "    W2         (latitude, longitude) float64 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0\n",
       "    W1         (latitude, longitude) float64 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0\n",
       "    Wr         (latitude, longitude) float64 -0.01508 -0.0156 ... 0.01022"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store the results from the regression in nc-files\n",
    "\n",
    "* 0: q\n",
    "* 1: t2m\n",
    "* 2: r\n",
    "* 3: sp\n",
    "* 4: bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inplace returns None\n",
    "encoding_dict = {}    \n",
    "for key in temp_dict.keys():\n",
    "    encoding_dict[key] = {'zlib': True, 'complevel': 9}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.to_netcdf(path = os.path.join(results_path,  'test.nc'),\n",
    "             engine='netcdf4',\n",
    "             encoding =encoding_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# include training periode in attributes and filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read results file and make a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = xr.open_dataset(os.path.join(results_path,  'test.nc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, coeffs):\n",
    "    \"\"\"Make prediction\"\"\"\n",
    "    return np.dot(X.T, coeffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Make prediction and calculate R2 and MSE both training and test\n",
    "### This file contains\n",
    "* MSE_train\n",
    "* MSE_test\n",
    "\n",
    "* R2_train\n",
    "* R2_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:    (latitude: 81, longitude: 161)\n",
       "Coordinates:\n",
       "  * latitude   (latitude) float64 30.0 30.25 30.5 30.75 ... 49.5 49.75 50.0\n",
       "  * longitude  (longitude) float64 -15.0 -14.75 -14.5 -14.25 ... 24.5 24.75 25.0\n",
       "Data variables:\n",
       "    b          (latitude, longitude) float64 ...\n",
       "    Wq         (latitude, longitude) float64 ...\n",
       "    Wt2m       (latitude, longitude) float64 ...\n",
       "    Wsp        (latitude, longitude) float64 ...\n",
       "    W3         (latitude, longitude) float64 ...\n",
       "    W2         (latitude, longitude) float64 ...\n",
       "    W1         (latitude, longitude) float64 ...\n",
       "    Wr         (latitude, longitude) float64 ..."
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(os.path.join(write_path, '2012_06_*.nc'))\n",
    "data = [xr.open_dataset(fil) for fil in files]\n",
    "most = xr.merge(data, 'equals')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:        (latitude: 81, longitude: 161, time: 720)\n",
       "Coordinates:\n",
       "  * latitude       (latitude) float64 30.0 30.25 30.5 30.75 ... 49.5 49.75 50.0\n",
       "  * time           (time) datetime64[ns] 2012-06-01 ... 2012-06-30T23:00:00\n",
       "    number         int64 0\n",
       "    step           timedelta64[ns] 00:00:00\n",
       "    isobaricInhPa  int64 1000\n",
       "  * longitude      (longitude) float64 -15.0 -14.75 -14.5 ... 24.5 24.75 25.0\n",
       "    valid_time     (time) datetime64[ns] 2012-06-01 ... 2012-06-30T23:00:00\n",
       "    surface        int64 0\n",
       "Data variables:\n",
       "    q              (time, latitude, longitude) float32 0.010645431 ... 0.010000957\n",
       "    r              (time, latitude, longitude) float32 79.789215 ... 73.236374\n",
       "    t2m            (time, latitude, longitude) float32 293.0703 ... 290.511\n",
       "    sp             (time, latitude, longitude) float32 101912.125 ... 98598.375\n",
       "    tcc            (time, latitude, longitude) float64 0.0 0.0 ... 1.0 1.0\n",
       "    nr_nans        (time, latitude, longitude) float64 0.0 0.0 0.0 ... 0.0 0.0"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9389520"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "81*161*720"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = most.tcc.values.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(81, 161)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "#temp.nanmean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation minimum which has no identity",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-223-425cbbe6b78c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/uio/hume/student-u89/hannasv/anaconda3/lib/python2.7/site-packages/seaborn/matrix.pyc\u001b[0m in \u001b[0;36mheatmap\u001b[0;34m(data, vmin, vmax, cmap, center, robust, annot, fmt, annot_kws, linewidths, linecolor, cbar, cbar_kws, cbar_ax, square, xticklabels, yticklabels, mask, ax, **kwargs)\u001b[0m\n\u001b[1;32m    515\u001b[0m     plotter = _HeatMapper(data, vmin, vmax, cmap, center, robust, annot, fmt,\n\u001b[1;32m    516\u001b[0m                           \u001b[0mannot_kws\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbar_kws\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxticklabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m                           yticklabels, mask)\n\u001b[0m\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m     \u001b[0;31m# Add the pcolormesh kwargs here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/uio/hume/student-u89/hannasv/anaconda3/lib/python2.7/site-packages/seaborn/matrix.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, vmin, vmax, cmap, center, robust, annot, fmt, annot_kws, cbar, cbar_kws, xticklabels, yticklabels, mask)\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;31m# Determine good default values for the colormapping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         self._determine_cmap_params(plot_data, vmin, vmax,\n\u001b[0;32m--> 167\u001b[0;31m                                     cmap, center, robust)\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;31m# Sort out the annotations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/uio/hume/student-u89/hannasv/anaconda3/lib/python2.7/site-packages/seaborn/matrix.pyc\u001b[0m in \u001b[0;36m_determine_cmap_params\u001b[0;34m(self, plot_data, vmin, vmax, cmap, center, robust)\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0mcalc_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplot_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplot_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvmin\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m             \u001b[0mvmin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpercentile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalc_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrobust\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mcalc_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvmax\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0mvmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpercentile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalc_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m98\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrobust\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mcalc_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/uio/hume/student-u89/hannasv/anaconda3/lib/python2.7/site-packages/numpy/core/_methods.pyc\u001b[0m in \u001b[0;36m_amin\u001b[0;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_amin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_minimum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: zero-size array to reduction operation minimum which has no identity"
     ]
    }
   ],
   "source": [
    "sns.heatmap(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable = results.variables.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare results to normalized predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data_for_prediction(data, order):\n",
    "    \"\"\" Preperation of data to make prediction\n",
    "    \n",
    "    data : xr.Dataset \n",
    "    \n",
    "    order : int\n",
    "        The n-th order of autoregressive model. Number of past cloud cover included.     \n",
    "    \"\"\"\n",
    "    \n",
    "    # Determine how many times have information about for cloud cover in 'order' previous steps.\n",
    "    X = None\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def results_to_numpy(data, weights):\n",
    "    \"\"\" Dataset. \n",
    "    Use weights to determine the order of the AR model.\n",
    "    \n",
    "    \n",
    "    data : xr.Dataset\n",
    "        contains the data you want to make a prediction on \n",
    "    \n",
    "    weights : xr.Dataset\n",
    "        Contains the weight and bias used to train this model.\n",
    "        \n",
    "    \"\"\" \n",
    "    weights_keys = weights.variables.keys()\n",
    "    \n",
    "    order = len(weights_keys) - 5\n",
    "    \n",
    "    # Call function which prepares the data to a format suitable to make a prediction. \n",
    "    # This involves \n",
    "    test_data = prep_data_for_prediction(data, order)\n",
    "    weights = pred_weights(weights)\n",
    "    \n",
    "    \n",
    "    \n",
    "    n = len(dataset.time.values)\n",
    "    \n",
    "    if bias:\n",
    "        num_vars = 4+1\n",
    "        \n",
    "    X = np.zeros((n, num_vars))\n",
    "    \n",
    "    q   = dataset.q.values\n",
    "    t2m = dataset.t2m.values\n",
    "    r   = dataset.r.values\n",
    "    sp  = dataset.sp.values\n",
    "    tcc = dataset.tcc.values\n",
    "    \n",
    "    X[:, 0] = q\n",
    "    X[:, 1] = t2m\n",
    "    X[:, 2] = r\n",
    "    X[:, 3] = sp\n",
    "    X[:, 4] = 1\n",
    "    return X, tcc[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:    (latitude: 81, longitude: 161)\n",
       "Coordinates:\n",
       "  * latitude   (latitude) float64 30.0 30.25 30.5 30.75 ... 49.5 49.75 50.0\n",
       "  * longitude  (longitude) float64 -15.0 -14.75 -14.5 -14.25 ... 24.5 24.75 25.0\n",
       "Data variables:\n",
       "    b          (latitude, longitude) float64 ...\n",
       "    Wq         (latitude, longitude) float64 ...\n",
       "    Wt2m       (latitude, longitude) float64 ...\n",
       "    Wsp        (latitude, longitude) float64 ...\n",
       "    W3         (latitude, longitude) float64 ...\n",
       "    W2         (latitude, longitude) float64 ...\n",
       "    W1         (latitude, longitude) float64 ...\n",
       "    Wr         (latitude, longitude) float64 ..."
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'b',\n",
       " u'Wq',\n",
       " u'Wt2m',\n",
       " u'Wsp',\n",
       " u'W3',\n",
       " u'W2',\n",
       " u'W1',\n",
       " u'Wr',\n",
       " u'latitude',\n",
       " u'longitude']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weights(dataset):\n",
    "    \"\"\"\n",
    "    weights: xr.Dataset\n",
    "        contains the weights and biases\n",
    "    \n",
    "    Returns\n",
    "    --------------\n",
    "    \n",
    "    X : weights in matrix for \n",
    "        \n",
    "    explenation : List[str]\n",
    "        Exlpaines the content in dimension 2.\n",
    "    \n",
    "    TODO: \n",
    "        Make sure they come in the correct oder\n",
    "        \n",
    "    \"\"\"\n",
    "    variables = dataset.variables.keys()    \n",
    "    X = np.zeros((n_lat, n_lon, len(variables)))\n",
    "    \n",
    "    W_q   = dataset.Wq.values\n",
    "    W_t2m = dataset.Wt2m.values\n",
    "    W_r   = dataset.Wr.values\n",
    "    W_sp  = dataset.Wsp.values\n",
    "    b = dataset.b.values\n",
    "    \n",
    "    X[:, :, 0] = W_q[:,:]\n",
    "    X[:, :, 1] = W_t2m[:,:]\n",
    "    X[:, :, 2] = W_r[:,:]\n",
    "    X[:, :, 3] = W_sp[:,:]\n",
    "    X[:, :, 4] = b # bias\n",
    "    \n",
    "    if len(variables) > 5+2: # 2 since it contains the latitude, longitude information.\n",
    "        for i in range(1, len(variables)-2-5+1):\n",
    "            var = 'W{}'.format(i)\n",
    "            X[:, :, i+4] = dataset[var].values                      \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results.Wq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create boolean arrays for detecting if one value has values back in time. \n",
    "# Create copies of the time axis and check if there is an hour between then "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predict_data(dataset, order):\n",
    "    \"\"\"\n",
    "    dataset : xr.Dataset\n",
    "        Contains the data you want to make a prediction based.\n",
    "    \n",
    "    TODO add explination column???\n",
    "        \n",
    "    keep the order of xarray time, lat, lon\n",
    "    \"\"\"\n",
    "    times = dataset.time.values\n",
    "    X = np.zeros( (len(times)-order, n_lat, n_lon, order+5) )\n",
    "    y = np.zeros( (len(times)-order, n_lat, n_lon) )\n",
    "    # X.shape = (lat, lon, variables, times) \n",
    "    \n",
    "    q   = dataset.q.values\n",
    "    t2m = dataset.t2m.values\n",
    "    r   = dataset.r.values\n",
    "    sp  = dataset.sp.values\n",
    "    tcc = dataset.tcc.values\n",
    "    \n",
    "    X[:, :, :, 0] = q[:-order,:,:]\n",
    "    X[:, :, :, 1] = t2m[:-order,:,:]\n",
    "    X[:, :, :, 2] = r[:-order,:,:]\n",
    "    X[:, :, :, 3] = sp[:-order,:,:]\n",
    "    X[:, :, :, 4] = 1 # bias\n",
    "    \n",
    "    y[:, :, :] = tcc[:-order]\n",
    "    \n",
    "    index = 5\n",
    "    \n",
    "    # tcc1, tcc2, ..., tcc_n\n",
    "    for temp_order in range(1, order+1):\n",
    "        a = times[:-temp_order]\n",
    "        b = times[temp_order:]\n",
    "        bo = [element.astype(int) == temp_order for element in (b-a).astype('timedelta64[h]') ]\n",
    "        \n",
    "        remove_from_end = order - temp_order\n",
    "        if remove_from_end != 0:\n",
    "            #remove_from_end = 1\n",
    "            # Which clouds to add at which column, remember that they shoudl start from t-1, t-2, t-3 ...  \n",
    "            X[:, :, :, index] = tcc[temp_order:, :, :][bo][:-remove_from_end, :, :]\n",
    "        else:\n",
    "            X[:, :, :, index] = tcc[temp_order:, :, :][bo]\n",
    "        index+=1     \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, true = get_predict_data(most, order=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(81, 161, 10)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = get_weights(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(X).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = get_weights(results)[:, :, :7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(81, 161, 7)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(718, 81, 161, 7)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = data[0, :, :, :]*X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(81, 161, 7)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_t0 = test.sum(axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = [(data[i, :, :, :]*X).sum(axis=2) for i in range(718)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(718, 81, 161)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(prediction).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_squared_error(y_true, y_pred):\n",
    "    \"\"\"Computes the Mean Squared Error score metric.\"\"\"\n",
    "    mse = np.square(np.subtract(y_true, y_pred)).mean(axis = 0)\n",
    "    return mse\n",
    "\n",
    "def r2_score(y_true, y_pred):\n",
    "    \"\"\"  \"\"\"\n",
    "    numerator = np.square(np.subtract(y_true, y_pred)).sum()\n",
    "    denominator = np.square(np.subtract(y_true, np.average(y_true))).sum()\n",
    "    val = numerator/denominator\n",
    "    return 1 - val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_true_values_to_compare_against():\n",
    "    # TODO tomorrow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(718, 81, 161)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(true, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       ...,\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan]])"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true.mean(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       ...,\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan]])"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
