{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dataloader import DataLoaderAR\n",
    "from AR_model   import AR_model\n",
    "# write_path = '/uio/lagringshotell/geofag/students/metos/hannasv/ERA5_monthly/'\n",
    "# read_path  = '/uio/lagringshotell/geofag/students/metos/hannasv/dataERA5_grib/'\n",
    "\n",
    "base = '/uio/lagringshotell/geofag/students/metos/hannasv/'\n",
    "base = '/home/hanna/lagrings'\n",
    "#read_path = '/uio/lagringshotell/geofag/students/metos/hannasv/dataERA5_grib/'\n",
    "read_folder = 'ERA5_monthly'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = os.path.join(base, read_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader AR?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = '2015_03'\n",
    "stop  = '2015_05'\n",
    "lat   = 30.0\n",
    "lon   = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hannasv/anaconda3/envs/sciclouds/lib/python3.6/site-packages/xarray/coding/times.py:207: FutureWarning: the 'box' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'box'\n",
      "  result = pd.to_timedelta(num_timedeltas, unit=units, box=False)\n",
      "/home/hannasv/anaconda3/envs/sciclouds/lib/python3.6/site-packages/xarray/coding/times.py:207: FutureWarning: the 'box' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'box'\n",
      "  result = pd.to_timedelta(num_timedeltas, unit=units, box=False)\n",
      "/home/hannasv/anaconda3/envs/sciclouds/lib/python3.6/site-packages/xarray/coding/times.py:207: FutureWarning: the 'box' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'box'\n",
      "  result = pd.to_timedelta(num_timedeltas, unit=units, box=False)\n",
      "/home/hannasv/anaconda3/envs/sciclouds/lib/python3.6/site-packages/xarray/coding/times.py:207: FutureWarning: the 'box' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'box'\n",
      "  result = pd.to_timedelta(num_timedeltas, unit=units, box=False)\n",
      "/home/hannasv/anaconda3/envs/sciclouds/lib/python3.6/site-packages/xarray/coding/times.py:207: FutureWarning: the 'box' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'box'\n",
      "  result = pd.to_timedelta(num_timedeltas, unit=units, box=False)\n",
      "/home/hannasv/anaconda3/envs/sciclouds/lib/python3.6/site-packages/xarray/coding/times.py:207: FutureWarning: the 'box' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'box'\n",
      "  result = pd.to_timedelta(num_timedeltas, unit=units, box=False)\n",
      "/home/hannasv/anaconda3/envs/sciclouds/lib/python3.6/site-packages/xarray/coding/times.py:207: FutureWarning: the 'box' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'box'\n",
      "  result = pd.to_timedelta(num_timedeltas, unit=units, box=False)\n",
      "/home/hannasv/anaconda3/envs/sciclouds/lib/python3.6/site-packages/xarray/coding/times.py:207: FutureWarning: the 'box' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'box'\n",
      "  result = pd.to_timedelta(num_timedeltas, unit=units, box=False)\n",
      "/home/hannasv/anaconda3/envs/sciclouds/lib/python3.6/site-packages/xarray/coding/times.py:207: FutureWarning: the 'box' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'box'\n",
      "  result = pd.to_timedelta(num_timedeltas, unit=units, box=False)\n",
      "/home/hannasv/anaconda3/envs/sciclouds/lib/python3.6/site-packages/xarray/coding/times.py:207: FutureWarning: the 'box' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'box'\n",
      "  result = pd.to_timedelta(num_timedeltas, unit=units, box=False)\n",
      "/home/hannasv/anaconda3/envs/sciclouds/lib/python3.6/site-packages/xarray/coding/times.py:207: FutureWarning: the 'box' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'box'\n",
      "  result = pd.to_timedelta(num_timedeltas, unit=units, box=False)\n"
     ]
    }
   ],
   "source": [
    "data_loader = DataLoaderAR(start = start, stop = stop, lat = lat, lon = lon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2208, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader.X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2208, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader.y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# files = glob.glob(os.path.join(read_path, '*.grib'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = xr.open_dataset(files[6], engine = 'cfgrib')\n",
    "domain = data.sel(latitude = slice(50,30), longitude = slice(-15, 25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_to_numpy(pixel, bias = True):\n",
    "    \"\"\" Dataset. \"\"\" \n",
    "    n = len(pixel.time.values)\n",
    "    \n",
    "    if bias:\n",
    "        num_vars = 4+1\n",
    "    X = np.zeros((n, num_vars))\n",
    "    \n",
    "    q   = pixel.q.values\n",
    "    t2m   = pixel.t2m.values\n",
    "    r   = pixel.r.values\n",
    "    sp  = pixel.sp.values\n",
    "    tcc = pixel.tcc.values\n",
    "        \n",
    "    X[:, 0] = q\n",
    "    X[:, 1] = t2m\n",
    "    X[:, 2] = r\n",
    "    X[:, 3] = sp\n",
    "    X[4, :] = 1\n",
    "    return X, tcc[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = 'r'\n",
    "months = np.arange(1, 13)\n",
    "#years = np.arange(2012, 2019)\n",
    "years=np.arange(2004, 2012)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in months:\n",
    "    for y in years:\n",
    "        subset = domain.sel(time = '{}-{:02d}'.format(y, m))\n",
    "        filename = '{}_{:02d}_{}.nc'.format(y, m, var)\n",
    "        eng = 'netcdf4'\n",
    "        encoding_dict = {'{}'.format(var): {'zlib': True, 'complevel': 9}}\n",
    "        subset.to_netcdf(os.path.join(write_path, filename), encoding=encoding_dict, engine = eng)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deal with missing values\n",
    "## Merge datasets and only keep the times present in both "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy \n",
    "\n",
    "write_path = '/uio/lagringshotell/geofag/students/metos/hannasv/ERA5_monthly/'\n",
    "read_path = '/uio/lagringshotell/geofag/students/metos/hannasv/dataERA5_grib/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = '/uio/lagringshotell/geofag/students/metos/hannasv/results/ar/models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store R2, MSE, Weights, \n",
    "# Names Wt2m, Wr, Wq, Wsp, W1, W2, .... Wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(os.path.join(write_path, '2012_05_*.nc'))\n",
    "data = [xr.open_dataset(fil) for fil in files]\n",
    "most = xr.merge(data, 'equals')\n",
    "res = np.zeros((n_lat, n_lon, len(coeffs)))\n",
    "latitudes = most.latitude.values\n",
    "longitudes = most.longitude.values\n",
    "    \n",
    "n_lat = 81\n",
    "n_lon = 161\n",
    "\n",
    "for i, lat in enumerate(latitudes): # 81\n",
    "    for j, lon in enumerate(longitudes): # 161\n",
    "\n",
    "        pixel = most.sel(latitude = lat, longitude = lon)\n",
    "        X, y = dataset_to_numpy(pixel)\n",
    "        coeffs = np.dot(inv(np.dot(X.T, X)), np.dot(X.T, y))\n",
    "        res[i, j, :] =  coeffs.flatten()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Merge the two dictionaries and make a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_dict = {}\n",
    "order = 3\n",
    "\n",
    "for i in range(order):\n",
    "    var = 'W{}'.format(i+1)\n",
    "    temp_dict[var] = (['latitude', 'longitude'], np.zeros((n_lat, n_lon)))\n",
    "    \n",
    "vars_dict = {'b': (['latitude', 'longitude'], res[:, :, 4]),\n",
    "             'Wt2m':(['latitude', 'longitude'], res[:, :, 1]),\n",
    "             'Wr': (['latitude', 'longitude'], res[:, :, 2]),\n",
    "             'Wq':(['latitude', 'longitude'], res[:, :, 0]),\n",
    "             'Wsp': (['latitude', 'longitude'], res[:, :, 3]),\n",
    "              }\n",
    "temp_dict.update(vars_dict)\n",
    "ds = xr.Dataset(temp_dict,\n",
    "                 coords={'longitude': (['longitude'], longitudes),\n",
    "                         'latitude': (['latitude'], latitudes),\n",
    "                        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store the results from the regression in nc-files\n",
    "\n",
    "* 0: q\n",
    "* 1: t2m\n",
    "* 2: r\n",
    "* 3: sp\n",
    "* 4: bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inplace returns None\n",
    "encoding_dict = {}    \n",
    "for key in temp_dict.keys():\n",
    "    encoding_dict[key] = {'zlib': True, 'complevel': 9}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.to_netcdf(path = os.path.join(results_path,  'test.nc'),\n",
    "             engine='netcdf4',\n",
    "             encoding =encoding_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# include training periode in attributes and filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read results file and make a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = xr.open_dataset(os.path.join(results_path,  'test.nc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, coeffs):\n",
    "    \"\"\"Make prediction\"\"\"\n",
    "    return np.dot(X.T, coeffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Make prediction and calculate R2 and MSE both training and test\n",
    "### This file contains\n",
    "* MSE_train\n",
    "* MSE_test\n",
    "\n",
    "* R2_train\n",
    "* R2_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(os.path.join(write_path, '2012_06_*.nc'))\n",
    "data = [xr.open_dataset(fil) for fil in files]\n",
    "most = xr.merge(data, 'equals')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "81*161*720"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = most.tcc.values.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#temp.nanmean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable = results.variables.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare results to normalized predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def results_to_numpy(data, weights):\n",
    "    \"\"\" Dataset. \n",
    "    Use weights to determine the order of the AR model.\n",
    "    \n",
    "    \n",
    "    data : xr.Dataset\n",
    "        contains the data you want to make a prediction on \n",
    "    \n",
    "    weights : xr.Dataset\n",
    "        Contains the weight and bias used to train this model.\n",
    "        \n",
    "    \"\"\" \n",
    "    weights_keys = weights.variables.keys()\n",
    "    \n",
    "    order = len(weights_keys) - 5\n",
    "    \n",
    "    # Call function which prepares the data to a format suitable to make a prediction. \n",
    "    # This involves \n",
    "    test_data = prep_data_for_prediction(data, order)\n",
    "    weights = pred_weights(weights)\n",
    "    \n",
    "    \n",
    "    \n",
    "    n = len(dataset.time.values)\n",
    "    \n",
    "    if bias:\n",
    "        num_vars = 4+1\n",
    "        \n",
    "    X = np.zeros((n, num_vars))\n",
    "    \n",
    "    q   = dataset.q.values\n",
    "    t2m = dataset.t2m.values\n",
    "    r   = dataset.r.values\n",
    "    sp  = dataset.sp.values\n",
    "    tcc = dataset.tcc.values\n",
    "    \n",
    "    X[:, 0] = q\n",
    "    X[:, 1] = t2m\n",
    "    X[:, 2] = r\n",
    "    X[:, 3] = sp\n",
    "    X[:, 4] = 1\n",
    "    return X, tcc[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weights(dataset):\n",
    "    \"\"\"\n",
    "    weights: xr.Dataset\n",
    "        contains the weights and biases\n",
    "    \n",
    "    Returns\n",
    "    --------------\n",
    "    \n",
    "    X : weights in matrix for \n",
    "        \n",
    "    explenation : List[str]\n",
    "        Exlpaines the content in dimension 2.\n",
    "    \n",
    "    TODO: \n",
    "        Make sure they come in the correct oder\n",
    "        \n",
    "    \"\"\"\n",
    "    variables = dataset.variables.keys()    \n",
    "    X = np.zeros((n_lat, n_lon, len(variables)))\n",
    "    \n",
    "    W_q   = dataset.Wq.values\n",
    "    W_t2m = dataset.Wt2m.values\n",
    "    W_r   = dataset.Wr.values\n",
    "    W_sp  = dataset.Wsp.values\n",
    "    b = dataset.b.values\n",
    "    \n",
    "    X[:, :, 0] = W_q[:,:]\n",
    "    X[:, :, 1] = W_t2m[:,:]\n",
    "    X[:, :, 2] = W_r[:,:]\n",
    "    X[:, :, 3] = W_sp[:,:]\n",
    "    X[:, :, 4] = b # bias\n",
    "    \n",
    "    if len(variables) > 5+2: # 2 since it contains the latitude, longitude information.\n",
    "        for i in range(1, len(variables)-2-5+1):\n",
    "            var = 'W{}'.format(i)\n",
    "            X[:, :, i+4] = dataset[var].values                      \n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_squared_error(y_true, y_pred):\n",
    "    \"\"\"Computes the Mean Squared Error score metric.\"\"\"\n",
    "    mse = np.square(np.subtract(y_true, y_pred)).mean(axis = 0)\n",
    "    return mse\n",
    "\n",
    "def r2_score(y_true, y_pred):\n",
    "    \"\"\"  \"\"\"\n",
    "    numerator = np.square(np.subtract(y_true, y_pred)).sum()\n",
    "    denominator = np.square(np.subtract(y_true, np.average(y_true))).sum()\n",
    "    val = numerator/denominator\n",
    "    return 1 - val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(true, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
