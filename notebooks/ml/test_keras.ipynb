{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt \n",
    "import xarray as xr\n",
    "import glob\n",
    "import numpy as np\n",
    "#import \n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters useful stuff - \n",
    "num_epochs = 4\n",
    "batch_size = 32\n",
    "#learning_rate = 0.001\n",
    "\n",
    "DATA_PATH = '/uio/lagringshotell/geofag/students/metos/hannasv/era_interim_data/'\n",
    "MODEL_STORE_PATH = '/uio/lagringshotell/geofag/students/metos/hannasv/era_interim_data/storedModel/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(start = \"2012-01-01\", stop = \"2019-01-01\", season = \"SON\", \n",
    "              era_path = '/uio/lagringshotell/geofag/students/metos/hannasv/era_interim_data/'):\n",
    "    \n",
    "    era_path = '/home/hanna/lagrings/era_interim_data/'\n",
    "    \"\"\" Want all year put season to. \"\"\"\n",
    "    assert len(glob.glob(era_path + \"*_q_*\" + season +\".nc\")), \"no data run cnct_lh in bash\"\n",
    "    #print(\n",
    "    q   = xr.open_dataset(glob.glob(era_path + \"*_q_*\" + season +\".nc\")[0]).q.values\n",
    "    r   = xr.open_dataset(glob.glob(era_path + \"*_r_*\"+ season +\".nc\")[0]).r.values\n",
    "    tcc = xr.open_dataset(glob.glob(era_path + \"*tcc*\"+ season +\".nc\")[0]).tcc.values\n",
    "    sp  = xr.open_dataset(glob.glob(era_path + \"*sp*\"+ season +\".nc\")[0]).sp.values\n",
    "    t2m = xr.open_dataset(glob.glob(era_path + \"*t2m*\"+ season +\".nc\")[0]).t2m.values\n",
    "    assert np.shape(q) == np.shape(r) == np.shape(tcc) == np.shape(sp) == np.shape(t2m)\n",
    "    \n",
    "    nbr_times, nbr_lats, nbr_lon = np.shape(q)\n",
    "    \n",
    "    train = []\n",
    "    true  = tcc[:, np.newaxis] # is wrong now\n",
    "    \n",
    "    \n",
    "    for i in range(nbr_times):\n",
    "        one_timestep = np.array([q[i], r[i], sp[i], t2m[i] ])\n",
    "        train.append(one_timestep)\n",
    "\n",
    "    return np.array(train), true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, true = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.1528546e-03, 7.2762016e+01, 9.8931422e+04, 2.8904562e+02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.mean(axis = 0).mean(axis=1).mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2184, 4, 35, 60)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(data, test_split = 0.2):\n",
    "    assert test_split < 1, 'test split is given as a decimal number, choose a number between 0, 1'\n",
    "    indx = int(len(data)*(1-test_split))\n",
    "    # returns train test\n",
    "    return data[:indx], data[indx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_normalize(data, seq_len = 4): \n",
    "    samples, metvars, lats, lons = data.shape\n",
    "    #.mean(axis = 0).mean(axis=1).mean(axis=1)\n",
    "    \n",
    "    normalized = np.zeros((samples, metvars, lats, lons))\n",
    "    means   = np.zeros(metvars)\n",
    "    storage = np.zeros(metvars)\n",
    "    \n",
    "    for i in range(metvars):\n",
    "        raveled = data[:, i, :, :].reshape(-1)\n",
    "        m = raveled.mean()\n",
    "        s = raveled.std()\n",
    "        normalized[:, i, :, :] =  (data[:, i, :, :] - m)/s\n",
    "        \n",
    "    samples, metvars, lats, lons = normalized.shape\n",
    "    assert seq_len % 4 == 0\n",
    "    \n",
    "    new_samples = int(samples/seq_len)\n",
    "    normalized  = normalized.reshape( (new_samples, seq_len, metvars, lats, lons ) )\n",
    "    \n",
    "    return normalized, means, storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import ConvLSTM2D\n",
    "#from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, means_x, storage_x = batch_normalize(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, means_y, storage_y = batch_normalize(true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(546, 4, 4, 35, 60)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# normalized, means, storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#units = normalized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cell = keras.layers.ConvLSTM2DCell(filters, kernel_size, strides=(1, 1), padding='same', data_format=None,\n",
    "#                            dilation_rate=(1, 1), activation='tanh', recurrent_activation='hard_sigmoid', \n",
    "#                            use_bias=True, kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal', \n",
    "#                            bias_initializer='zeros', unit_forget_bias=True, kernel_regularizer=None,\n",
    "#                            recurrent_regularizer=None, bias_regularizer=None, \n",
    "#                            kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, \n",
    "#                            dropout=0.0, recurrent_dropout=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcMB( l ):\n",
    "    \"\"\"Returnes the megabytes of memory this data uses.\n",
    "    Use this to detemine the batch..?\n",
    "    \"\"\"\n",
    "    size = np.array(l.shape)\n",
    "    return np.prod(size)*8\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((546, 4, 4, 35, 60), (546, 4, 1, 35, 60))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = x.reshape(-1, 2184, 4, 35, 60)\n",
    "#y = y.reshape(-1, 2184, 1, 35, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import ConvLSTM2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "\n",
    "#from keras.layers import keras.layers.\n",
    "\n",
    "model1 =  Sequential()\n",
    "\n",
    "# Begin with 2D convolutional LSTM layer\n",
    "model1.add(ConvLSTM2D(filters = 256, kernel_size = (3, 3),\n",
    "                     input_shape = (4, 4, 35, 60),\n",
    "                     padding = 'same', return_sequences=True, data_format='channels_first')) \n",
    "\n",
    "model1.add(keras.layers.ConvLSTM2D(filters = 128, kernel_size = (3, 3),\n",
    "                                  #input_shape = (256, 35, 60, 1),\n",
    "                                  padding='same', return_sequences=True,  data_format='channels_first')) \n",
    "\n",
    "model1.add(keras.layers.ConvLSTM2D(filters=64, kernel_size=(3, 3),\n",
    "                                  #input_shape=(None, 35, 60, 1),\n",
    "                                  padding='same', return_sequences=True,  data_format='channels_first')) \n",
    "\n",
    "# Add 3x hidden 2D convolutions LSTM layers    \n",
    "# Begin with 2D convolutional LSTM layer\n",
    "model1.add(keras.layers.ConvLSTM2D(filters=1, kernel_size=(3, 3), # (1, 1)\n",
    "                                  #input_shape=(None, 40, 40, 1),\n",
    "                                  padding='same', return_sequences=True,  data_format='channels_first')) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in model.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(history):\n",
    "    # Plot training & validation loss values\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras.utils import plot_model\n",
    "#plot_model(model, to_file=save_dir+'model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datetime in /home/hanna/.local/lib/python3.5/site-packages (4.3)\n",
      "Requirement already satisfied: zope.interface in /home/hanna/.local/lib/python3.5/site-packages (from datetime) (4.6.0)\n",
      "Requirement already satisfied: pytz in /home/hanna/.local/lib/python3.5/site-packages (from datetime) (2019.3)\n",
      "Requirement already satisfied: setuptools in /home/hanna/.local/lib/python3.5/site-packages (from zope.interface->datetime) (41.4.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install datetime --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 436 samples, validate on 110 samples\n",
      "Epoch 1/4\n"
     ]
    }
   ],
   "source": [
    "# Prepare model for training\n",
    "model1.compile(\n",
    "      loss = \"mse\",\n",
    "      metrics = [\"mae\"],\n",
    "      optimizer = \"adam\"\n",
    ")\n",
    "import datetime\n",
    "log_dir=\"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "\n",
    "history = model1.fit(x,\n",
    "                    y,\n",
    "                    batch_size = 32,\n",
    "                    epochs = 4,\n",
    "                    validation_split = 0.2,\n",
    "                    callbacks=[tensorboard_callback]\n",
    "                    )\n",
    "\n",
    "plot(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-7a043b5ce57d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConvLSTM2D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#from keras.layers.normalization import BatchNormalization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#from keras.layers import keras.layers.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "from tensorkeras.models import Sequential\n",
    "from keras.layers import ConvLSTM2D\n",
    "#from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "#from keras.layers import keras.layers.\n",
    "\n",
    "def build_model(filters = [256, 128, 64], kernal = [5, 5, 3], input_shape = (4, 4, 35, 60)):\n",
    "    model =  Sequential()\n",
    "\n",
    "    # Begin with 2D convolutional LSTM layer\n",
    "    for i, filter_ in enumerate( filters ):\n",
    "        k_s = kernal[i]\n",
    "        \n",
    "        if i == 0:\n",
    "            model.add(ConvLSTM2D(filters = filter_, kernel_size = (k_s, k_s),\n",
    "                                 input_shape = input_shape,\n",
    "                                 padding = 'same', return_sequences=True, data_format='channels_first')) \n",
    "        else:\n",
    "            model.add(ConvLSTM2D(filters = filter_, kernel_size =  (k_s, k_s),\n",
    "                                              #input_shape = (256, 35, 60, 1),\n",
    "                                              padding='same', return_sequences=True,  data_format='channels_first')) \n",
    "\n",
    "    # Add 3x hidden 2D convolutions LSTM layers    \n",
    "    # Begin with 2D convolutional LSTM layer\n",
    "    # Blir dette rett da..?\n",
    "    model.add(keras.layers.ConvLSTM2D(filters=1, kernel_size=(1, 1),\n",
    "                                      #input_shape=(None, 40, 40, 1),\n",
    "                                      padding='same', return_sequences=True,  data_format='channels_first')) \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f8070d3fca51>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvolutional_recurrent\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConvLSTM2D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalization\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBatchNormalization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#from keras.layers import keras.layers.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model =  Sequential()\n",
    "\n",
    "# Begin with 2D convolutional LSTM layer\n",
    "model.add(ConvLSTM2D(filters = 256, kernel_size = (5, 5),\n",
    "                     input_shape = (4, 4, 35, 60),\n",
    "                     padding = 'same', return_sequences=True, data_format='channels_first')) \n",
    "\n",
    "model.add(keras.layers.ConvLSTM2D(filters = 128, kernel_size = (5, 5),\n",
    "                                  #input_shape = (256, 35, 60, 1),\n",
    "                                  padding='same', return_sequences=True,  data_format='channels_first')) \n",
    "\n",
    "model.add(keras.layers.ConvLSTM2D(filters=64, kernel_size=(3, 3),\n",
    "                                  #input_shape=(None, 35, 60, 1),\n",
    "                                  padding='same', return_sequences=True,  data_format='channels_first')) \n",
    "\n",
    "# Add 3x hidden 2D convolutions LSTM layers    \n",
    "# Begin with 2D convolutional LSTM layer\n",
    "model.add(keras.layers.ConvLSTM2D(filters=1, kernel_size=(3, 3),\n",
    "                                  #input_shape=(None, 40, 40, 1),\n",
    "                                  padding='same', return_sequences=True,  data_format='channels_first')) \n",
    "\n",
    "# Prepare model for training\n",
    "model.compile(\n",
    "      loss = \"mse\",\n",
    "      metrics = [\"mae\"],\n",
    "      optimizer = \"adam\"\n",
    ")\n",
    "\n",
    "history2 = model.fit(x,\n",
    "                    y,\n",
    "                    batch_size = 32,\n",
    "                    epochs = 40,\n",
    "                    validation_split = 0.2, \n",
    "                    callbacks=[tensorboard_callback]\n",
    "                    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(history2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "\n",
    "\n",
    "def save_json(model, m = \"model.json\"):    \n",
    "    \"\"\" Storing a config / architecture of the model.\"\"\"\n",
    "    # serialize model to JSON\n",
    "    model_json = model.to_json()\n",
    "    with open(m, \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    return\n",
    "\n",
    "def load_model(m = 'model.json'):\n",
    "    \"\"\" Loading a stored config/ architecture  to a model. \"\"\"\n",
    "    # load json and create model\n",
    "    json_file = open(m, 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    return loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_storage = '/home/hanna/MS/stored_models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_json( model, model_storage + \"example_keras.json\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(  model_storage + \"example_keras.json\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(model_storage + \"example_keras.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(model_storage + \"example_keras.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement your own/ Custumize metrics  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
