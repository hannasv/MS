{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install netcdf4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import LSTM\n",
    "import xarray as xr\n",
    "import glob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters useful stuff - \n",
    "num_epochs = 40\n",
    "batch_size = 32\n",
    "#learning_rate = 0.001\n",
    "\n",
    "DATA_PATH = '/uio/lagringshotell/geofag/students/metos/hannasv/era_interim_data/'\n",
    "MODEL_STORE_PATH = '/uio/lagringshotell/geofag/students/metos/hannasv/era_interim_data/storedModel/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(start = \"2012-01-01\", stop = \"2019-01-01\", season = \"SON\", \n",
    "              era_path = '/uio/lagringshotell/geofag/students/metos/hannasv/era_interim_data/'):\n",
    "    \n",
    "    era_path = '/home/hanna/lagrings/era_interim_data/'\n",
    "    \"\"\" Want all year put season to. \"\"\"\n",
    "    print(glob.glob(era_path + \"*_q_*\" + season +\".nc\"))\n",
    "    q   = xr.open_dataset(glob.glob(era_path + \"*_q_*\" + season +\".nc\")[0]).q.values\n",
    "    r   = xr.open_dataset(glob.glob(era_path + \"*_r_*\"+ season +\".nc\")[0]).r.values\n",
    "    tcc = xr.open_dataset(glob.glob(era_path + \"*tcc*\"+ season +\".nc\")[0]).tcc.values\n",
    "    sp  = xr.open_dataset(glob.glob(era_path + \"*sp*\"+ season +\".nc\")[0]).sp.values\n",
    "    t2m = xr.open_dataset(glob.glob(era_path + \"*t2m*\"+ season +\".nc\")[0]).t2m.values\n",
    "    assert np.shape(q) == np.shape(r) == np.shape(tcc) == np.shape(sp) == np.shape(t2m)\n",
    "    \n",
    "    nbr_times, nbr_lats, nbr_lon = np.shape(q)\n",
    "    \n",
    "    train = []\n",
    "    true  = tcc[:, np.newaxis] # is wrong now\n",
    "    \n",
    "    \n",
    "    for i in range(nbr_times):\n",
    "        one_timestep = np.array([q[i], r[i], sp[i], t2m[i] ])\n",
    "        train.append(one_timestep)\n",
    "\n",
    "    return np.array(train), true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/hanna/lagrings/era_interim_data/raw_1979-01-01_2018-12-31_q_all_cropped_SON.nc']\n"
     ]
    }
   ],
   "source": [
    "train, true = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-3fac96d4fc3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "train.mean(axis = 0).mean(axis=1).mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2184, 4, 35, 60)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(data, test_split = 0.2):\n",
    "    assert test_split < 1, 'test split is given as a decimal number, choose a number between 0, 1'\n",
    "    indx = int(len(data)*(1-test_split))\n",
    "    # returns train test\n",
    "    return data[:indx], data[indx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_normalize(data, seq_len = 4): \n",
    "    samples, metvars, lats, lons = data.shape\n",
    "    #.mean(axis = 0).mean(axis=1).mean(axis=1)\n",
    "    \n",
    "    normalized = np.zeros((samples, metvars, lats, lons))\n",
    "    means   = np.zeros(metvars)\n",
    "    storage = np.zeros(metvars)\n",
    "    \n",
    "    for i in range(metvars):\n",
    "        raveled = data[:, i, :, :].reshape(-1)\n",
    "        m = raveled.mean()\n",
    "        s = raveled.std()\n",
    "        normalized[:, i, :, :] =  (data[:, i, :, :] - m)/s\n",
    "        \n",
    "    samples, metvars, lats, lons = normalized.shape\n",
    "    assert seq_len % 4 == 0\n",
    "    \n",
    "    new_samples = int(samples/seq_len)\n",
    "    normalized  = normalized.reshape( (new_samples, seq_len, metvars, lats, lons ) )\n",
    "    \n",
    "    return normalized, means, storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.convolutional_recurrent import ConvLSTM2D\n",
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, means_x, storage_x = batch_normalize(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, means_y, storage_y = batch_normalize(true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(546, 4, 4, 35, 60)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# normalized, means, storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "units = normalized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cell = keras.layers.ConvLSTM2DCell(filters, kernel_size, strides=(1, 1), padding='same', data_format=None,\n",
    "#                            dilation_rate=(1, 1), activation='tanh', recurrent_activation='hard_sigmoid', \n",
    "#                            use_bias=True, kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal', \n",
    "#                            bias_initializer='zeros', unit_forget_bias=True, kernel_regularizer=None,\n",
    "#                            recurrent_regularizer=None, bias_regularizer=None, \n",
    "#                            kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, \n",
    "#                            dropout=0.0, recurrent_dropout=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2184, 4, 35, 60), (2184, 1, 35, 60))"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = x.reshape(-1, 2184, 4, 35, 60)\n",
    "#y = y.reshape(-1, 2184, 1, 35, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/hanna/anaconda3/envs/keras_env/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/hanna/anaconda3/envs/keras_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 436 samples, validate on 110 samples\n",
      "Epoch 1/40\n",
      "436/436 [==============================] - 1111s 3s/step - loss: 0.8780 - mae: 0.8287 - val_loss: 0.7848 - val_mae: 0.7709\n",
      "Epoch 2/40\n",
      "436/436 [==============================] - 1158s 3s/step - loss: 0.7800 - mae: 0.7588 - val_loss: 0.7173 - val_mae: 0.7283\n",
      "Epoch 3/40\n",
      "436/436 [==============================] - 1156s 3s/step - loss: 0.7437 - mae: 0.7343 - val_loss: 0.6998 - val_mae: 0.7181\n",
      "Epoch 4/40\n",
      " 32/436 [=>............................] - ETA: 16:40 - loss: 0.6879 - mae: 0.7011"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional_recurrent import ConvLSTM2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "#from keras.layers import keras.layers.\n",
    "\n",
    "model =  Sequential()\n",
    "\n",
    "# Begin with 2D convolutional LSTM layer\n",
    "model.add(ConvLSTM2D(filters = 256, kernel_size = (3, 3),\n",
    "                     input_shape = (4, 4, 35, 60),\n",
    "                     padding = 'same', return_sequences=True, data_format='channels_first')) \n",
    "\n",
    "model.add(keras.layers.ConvLSTM2D(filters = 128, kernel_size = (3, 3),\n",
    "                                  #input_shape = (256, 35, 60, 1),\n",
    "                                  padding='same', return_sequences=True,  data_format='channels_first')) \n",
    "\n",
    "model.add(keras.layers.ConvLSTM2D(filters=64, kernel_size=(3, 3),\n",
    "                                  #input_shape=(None, 35, 60, 1),\n",
    "                                  padding='same', return_sequences=True,  data_format='channels_first')) \n",
    "\n",
    "# Add 3x hidden 2D convolutions LSTM layers    \n",
    "# Begin with 2D convolutional LSTM layer\n",
    "model.add(keras.layers.ConvLSTM2D(filters=1, kernel_size=(3, 3),\n",
    "                                  #input_shape=(None, 40, 40, 1),\n",
    "                                  padding='same', return_sequences=True,  data_format='channels_first')) \n",
    "# Prepare model for training\n",
    "model.compile(\n",
    "      loss = \"mse\",\n",
    "      metrics = [\"mae\"],\n",
    "      optimizer = \"adam\"\n",
    ")\n",
    "\n",
    "history = model.fit(x,\n",
    "                    y,\n",
    "                    batch_size = 32,\n",
    "                    epochs = 40,\n",
    "                    validation_split = 0.2,\n",
    "                    )\n",
    "\n",
    "plot(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Add 3x hidden 2D convolutions LSTM layers\n",
    "# Begin with 2D convolutional LSTM layer\n",
    "model.add(keras.layers.ConvLSTM2DCell(filters = 128, kernel_size=(3,3), strides=(1, 1), padding='same', data_format=None,\n",
    "                            dilation_rate=(1, 1), activation='tanh', recurrent_activation='hard_sigmoid', \n",
    "                            use_bias=True, kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal', \n",
    "                            bias_initializer='zeros', unit_forget_bias=True, kernel_regularizer=None,\n",
    "                            recurrent_regularizer=None, bias_regularizer=None, \n",
    "                            kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, \n",
    "                            dropout=0.0, recurrent_dropout=0.0) )\n",
    "\n",
    "# Begin with 2D convolutional LSTM layer\n",
    "model.add(keras.layers.ConvLSTM2D(filters = 64, kernel_size=(3,3), strides=(1, 1), padding='same', data_format=None,\n",
    "                            dilation_rate=(1, 1), activation='tanh', recurrent_activation='hard_sigmoid', \n",
    "                            use_bias=True, kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal', \n",
    "                            bias_initializer='zeros', unit_forget_bias=True, kernel_regularizer=None,\n",
    "                            recurrent_regularizer=None, bias_regularizer=None, \n",
    "                            kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, \n",
    "                            dropout=0.0, recurrent_dropout=0.0) )\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
