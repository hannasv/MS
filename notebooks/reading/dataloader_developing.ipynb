{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "import xarray as xr\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_m = '/home/hannasv/Desktop/lagrings/ERA5_monthly/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = '2005-05'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data exploration we want to study :\n",
    "* Correlation pixelwise to pressure\n",
    "* Everything as a mean over time \n",
    "* Hvordan dele opp dataen slik at det kan leses inn best mulig. \n",
    "* Hugo minnet sette begrensninger for AR - models med invers matrise?\n",
    "* Hvor mye data har jeg egentlig?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters useful stuff - \n",
    "num_epochs = 4\n",
    "batch_size = 32\n",
    "#learning_rate = 0.001\n",
    "\n",
    "#DATA_PATH = '/uio/lagringshotell/geofag/students/metos/hannasv/era_interim_data/'\n",
    "#MODEL_STORE_PATH = '/uio/lagringshotell/geofag/students/metos/hannasv/era_interim_data/storedModel/'\n",
    "\n",
    "DATA_PATH = '/uio/lagringshotell/geofag/students/metos/hannasv/era_interim_data/'\n",
    "MODEL_STORE_PATH = '/uio/lagringshotell/geofag/students/metos/hannasv/era_interim_data/storedModel/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'03'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"%2.2d\" %3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'2012_02' < '2012_01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files(start, stop):\n",
    "    \"\"\" Get files in requested period.\n",
    "    Insert test on start > stop. \n",
    "    \n",
    "    Returns:\n",
    "        List of files to be read into \n",
    "    \n",
    "    \"\"\"\n",
    "    y, m = start.split('_')\n",
    "    start_y = int(y)\n",
    "    start_m = int(m)\n",
    "    \n",
    "    y, m = stop.split('_')\n",
    "    stop_y = int(y)\n",
    "    stop_m = int(m)\n",
    "\n",
    "    years = np.arange(start_y, stop_y+1)\n",
    "    months = np.arange(1, 13)  \n",
    "    search_str = [start, stop]\n",
    "    \n",
    "    for y in years:\n",
    "        for m in months:\n",
    "            m = \"%2.2d\" %m\n",
    "            tmp = '{}_{}'.format(y, m)\n",
    "            if tmp > start and tmp < stop:\n",
    "                search_str.append(tmp)   \n",
    "    \n",
    "    storage = '/home/hannasv/Desktop/lagrings/ERA5_monthly/'\n",
    "    \n",
    "    files = []\n",
    "    for ss in search_str:\n",
    "        tmp_files = glob.glob(os.path.join( storage, '*{}*.nc'.format(ss)  ))  \n",
    "        files += tmp_files\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_files('2012_03', '2014_01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loader of AR \n",
    "\n",
    "def load_data_AR(start, stop, lat, lon, num_ts = 0, bias = True, validation_split = 0.0):\n",
    "    \"\"\" Prepares data for \n",
    "    \n",
    "    start, stop : str\n",
    "        year_month. Limited to montly values.\n",
    "        \n",
    "    lat, lon : float\n",
    "        coordinate information\n",
    "        \n",
    "    bias : bool \n",
    "        Default 1\n",
    "        \n",
    "    validation_split : float\n",
    "        Number between 0 and 1. \n",
    "        Intended to make it similar to keras input data. Will it make it easier to train networks though...?\n",
    "    \"\"\"\n",
    "    if validation_split > 0:\n",
    "        raise NotImplementedError('Comming soon ... Make sure that you actually need this?')\n",
    "        \n",
    "    # Search for list of files in the range start stop.\n",
    "    # Returns list of strings you can merge to a dataset \n",
    "    \n",
    "    files = get_files(start, stop)\n",
    "    datasets = [ xr.open_dataset(fil).sel(latitude = lat, longitude = lon) for fil in files]\n",
    "    data = xr.merge(datasets,                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 'equals') # fill_value = np.nan,\n",
    "    print(data)\n",
    "    n     = len(data.time.values)\n",
    "    n_lat = len(data.latitude.values)\n",
    "    n_lon = len(data.longitude.values)\n",
    "    \n",
    "    q   = data.q.values\n",
    "    t2m = data.t2m.values\n",
    "    r   = data.r.values\n",
    "    sp  = data.sp.values\n",
    "    \n",
    "    tcc = data.tcc.values\n",
    "    \n",
    "    if bias:\n",
    "        num_vars = 4+1+num_ts\n",
    "    else:\n",
    "        num_vars = 4 + num_ts\n",
    "        \n",
    "    num_samples = n - num_ts\n",
    "    X = np.zeros((num_samples, n_lat, n_lon, num_vars))\n",
    "    \n",
    "    X[:, :, :, 0] = 1\n",
    "    X[:, :, :, 1] = t2m\n",
    "    X[:, :, :, 2] = r\n",
    "    X[:, :, :, 3] = sp\n",
    "    X[:, :, :, 4] = q\n",
    "    \n",
    "    for i in range(1, num_ts+1):\n",
    "        if num_ts - i != 0:\n",
    "            X[:, :, :, 4+i] = tcc[i:num_ts-i]\n",
    "        else:\n",
    "            X[:, :, :, 4+i] = tcc[i:]\n",
    "    # Now drop rows contaning nans.\n",
    "    print(X.shape)\n",
    "    no_nans =  X[~np.isnan(X.any(axis=1))]\n",
    "    print(no_nans.shape)\n",
    "    return no_nans\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "start='2012_02'\n",
    "stop='2012_04'\n",
    "\n",
    "lat=30\n",
    "lon = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mxr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'no_conflicts'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'outer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Merge any number of xarray objects into a single Dataset as variables.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "objects : Iterable[Union[xarray.Dataset, xarray.DataArray, dict]]\n",
       "    Merge together all variables from these objects. If any of them are\n",
       "    DataArray objects, they must have a name.\n",
       "compat : {'identical', 'equals', 'broadcast_equals',\n",
       "          'no_conflicts'}, optional\n",
       "    String indicating how to compare variables of the same name for\n",
       "    potential conflicts:\n",
       "\n",
       "    - 'broadcast_equals': all values must be equal when variables are\n",
       "      broadcast against each other to ensure common dimensions.\n",
       "    - 'equals': all values and dimensions must be the same.\n",
       "    - 'identical': all values, dimensions and attributes must be the\n",
       "      same.\n",
       "    - 'no_conflicts': only values which are not null in both datasets\n",
       "      must be equal. The returned dataset then contains the combination\n",
       "      of all non-null values.\n",
       "join : {'outer', 'inner', 'left', 'right', 'exact'}, optional\n",
       "    How to combine objects with different indexes.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "Dataset\n",
       "    Dataset with combined variables from each object.\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> arrays = [xr.DataArray(n, name='var%d' % n) for n in range(5)]\n",
       ">>> xr.merge(arrays)\n",
       "<xarray.Dataset>\n",
       "Dimensions:  ()\n",
       "Coordinates:\n",
       "    *empty*\n",
       "Data variables:\n",
       "    var0     int64 0\n",
       "    var1     int64 1\n",
       "    var2     int64 2\n",
       "    var3     int64 3\n",
       "    var4     int64 4\n",
       "\n",
       "Raises\n",
       "------\n",
       "xarray.MergeError\n",
       "    If any variables with the same name have conflicting values.\n",
       "\n",
       "See also\n",
       "--------\n",
       "concat\n",
       "\u001b[0;31mFile:\u001b[0m      ~/anaconda3/envs/sciclouds/lib/python3.6/site-packages/xarray/core/merge.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xr.merge?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:        (time: 2160)\n",
      "Coordinates:\n",
      "  * time           (time) datetime64[ns] 2012-02-01 2012-02-01T01:00:00 ...\n",
      "    number         int64 0\n",
      "    step           timedelta64[ns] 00:00:00\n",
      "    isobaricInhPa  int64 1000\n",
      "    latitude       float64 30.0\n",
      "    longitude      float64 15.0\n",
      "    valid_time     (time) datetime64[ns] 2012-02-01 2012-02-01T01:00:00 ...\n",
      "    surface        int64 0\n",
      "Data variables:\n",
      "    q              (time) float32 0.00534194 0.00553718 0.0056997 0.00581151 ...\n",
      "    r              (time) float32 70.2913 75.9101 80.5836 85.3799 88.4248 ...\n",
      "    t2m            (time) float32 282.83 282.76 282.2 281.418 281.33 281.021 ...\n",
      "    sp             (time) float32 98076.2 98076.0 98059.1 98057.2 98028.9 ...\n",
      "    tcc            (time) float64 0.5511 0.6288 0.5274 0.4335 0.4199 0.5349 ...\n",
      "    nr_nans        (time) float64 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 ...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "len() of unsized object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-f844cb88e61f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mload_data_AR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_ts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-43-a23cd05085f8>\u001b[0m in \u001b[0;36mload_data_AR\u001b[0;34m(start, stop, lat, lon, num_ts, bias, validation_split)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mn\u001b[0m     \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mn_lat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatitude\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0mn_lon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlongitude\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: len() of unsized object"
     ]
    }
   ],
   "source": [
    "load_data_AR(start, stop, lat, lon, num_ts = 0, bias = True, validation_split = 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start, stop, lat, lon, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-47-98cdb47d82e5>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-47-98cdb47d82e5>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    MergeError: conflicting values for variable 'valid_time' on objects to be combined:\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "MergeError: conflicting values for variable 'valid_time' on objects to be combined:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a plot containing the sum of all nans over all gridded times¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(os.path.join( data_m, \"*2007_08*.nc\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = xr.open_dataset(files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:        (latitude: 81, longitude: 161, time: 744)\n",
       "Coordinates:\n",
       "    number         int64 ...\n",
       "  * time           (time) datetime64[ns] 2007-08-01 2007-08-01T01:00:00 ...\n",
       "    step           timedelta64[ns] ...\n",
       "    isobaricInhPa  int64 ...\n",
       "  * latitude       (latitude) float64 50.0 49.75 49.5 49.25 49.0 48.75 48.5 ...\n",
       "  * longitude      (longitude) float64 -15.0 -14.75 -14.5 -14.25 -14.0 ...\n",
       "    valid_time     (time) datetime64[ns] ...\n",
       "Data variables:\n",
       "    r              (time, latitude, longitude) float32 ...\n",
       "Attributes:\n",
       "    GRIB_edition:            1\n",
       "    GRIB_centre:             ecmf\n",
       "    GRIB_centreDescription:  European Centre for Medium-Range Weather Forecasts\n",
       "    GRIB_subCentre:          0\n",
       "    Conventions:             CF-1.7\n",
       "    institution:             European Centre for Medium-Range Weather Forecasts\n",
       "    history:                 2020-02-20T19:31:32 GRIB to CDM+CF via cfgrib-0...."
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [ xr.open_dataset(fil) for fil in files  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:        (latitude: 81, longitude: 161, time: 744)\n",
      "Coordinates:\n",
      "    number         int64 ...\n",
      "  * time           (time) datetime64[ns] 2007-08-01 2007-08-01T01:00:00 ...\n",
      "    step           timedelta64[ns] ...\n",
      "    isobaricInhPa  int64 ...\n",
      "  * latitude       (latitude) float64 50.0 49.75 49.5 49.25 49.0 48.75 48.5 ...\n",
      "  * longitude      (longitude) float64 -15.0 -14.75 -14.5 -14.25 -14.0 ...\n",
      "    valid_time     (time) datetime64[ns] ...\n",
      "Data variables:\n",
      "    r              (time, latitude, longitude) float32 ...\n",
      "Attributes:\n",
      "    GRIB_edition:            1\n",
      "    GRIB_centre:             ecmf\n",
      "    GRIB_centreDescription:  European Centre for Medium-Range Weather Forecasts\n",
      "    GRIB_subCentre:          0\n",
      "    Conventions:             CF-1.7\n",
      "    institution:             European Centre for Medium-Range Weather Forecasts\n",
      "    history:                 2020-02-20T19:31:32 GRIB to CDM+CF via cfgrib-0....\n",
      "<xarray.Dataset>\n",
      "Dimensions:     (latitude: 81, longitude: 161, time: 744)\n",
      "Coordinates:\n",
      "    number      int64 ...\n",
      "  * time        (time) datetime64[ns] 2007-08-01 2007-08-01T01:00:00 ...\n",
      "    step        timedelta64[ns] ...\n",
      "    surface     int64 ...\n",
      "  * latitude    (latitude) float64 50.0 49.75 49.5 49.25 49.0 48.75 48.5 ...\n",
      "  * longitude   (longitude) float64 -15.0 -14.75 -14.5 -14.25 -14.0 -13.75 ...\n",
      "    valid_time  (time) datetime64[ns] ...\n",
      "Data variables:\n",
      "    t2m         (time, latitude, longitude) float32 ...\n",
      "Attributes:\n",
      "    GRIB_edition:            1\n",
      "    GRIB_centre:             ecmf\n",
      "    GRIB_centreDescription:  European Centre for Medium-Range Weather Forecasts\n",
      "    GRIB_subCentre:          0\n",
      "    Conventions:             CF-1.7\n",
      "    institution:             European Centre for Medium-Range Weather Forecasts\n",
      "    history:                 2020-02-20T12:41:50 GRIB to CDM+CF via cfgrib-0....\n",
      "<xarray.Dataset>\n",
      "Dimensions:        (latitude: 81, longitude: 161, time: 744)\n",
      "Coordinates:\n",
      "    number         int64 ...\n",
      "  * time           (time) datetime64[ns] 2007-08-01 2007-08-01T01:00:00 ...\n",
      "    step           timedelta64[ns] ...\n",
      "    isobaricInhPa  int64 ...\n",
      "  * latitude       (latitude) float64 50.0 49.75 49.5 49.25 49.0 48.75 48.5 ...\n",
      "  * longitude      (longitude) float64 -15.0 -14.75 -14.5 -14.25 -14.0 ...\n",
      "    valid_time     (time) datetime64[ns] ...\n",
      "Data variables:\n",
      "    q              (time, latitude, longitude) float32 ...\n",
      "Attributes:\n",
      "    GRIB_edition:            1\n",
      "    GRIB_centre:             ecmf\n",
      "    GRIB_centreDescription:  European Centre for Medium-Range Weather Forecasts\n",
      "    GRIB_subCentre:          0\n",
      "    Conventions:             CF-1.7\n",
      "    institution:             European Centre for Medium-Range Weather Forecasts\n",
      "    history:                 2020-02-20T13:49:04 GRIB to CDM+CF via cfgrib-0....\n",
      "<xarray.Dataset>\n",
      "Dimensions:     (latitude: 81, longitude: 161, time: 744)\n",
      "Coordinates:\n",
      "    number      int64 ...\n",
      "  * time        (time) datetime64[ns] 2007-08-01 2007-08-01T01:00:00 ...\n",
      "    step        timedelta64[ns] ...\n",
      "    surface     int64 ...\n",
      "  * latitude    (latitude) float64 50.0 49.75 49.5 49.25 49.0 48.75 48.5 ...\n",
      "  * longitude   (longitude) float64 -15.0 -14.75 -14.5 -14.25 -14.0 -13.75 ...\n",
      "    valid_time  (time) datetime64[ns] ...\n",
      "Data variables:\n",
      "    sp          (time, latitude, longitude) float32 ...\n",
      "Attributes:\n",
      "    GRIB_edition:            1\n",
      "    GRIB_centre:             ecmf\n",
      "    GRIB_centreDescription:  European Centre for Medium-Range Weather Forecasts\n",
      "    GRIB_subCentre:          0\n",
      "    Conventions:             CF-1.7\n",
      "    institution:             European Centre for Medium-Range Weather Forecasts\n",
      "    history:                 2020-02-20T14:17:49 GRIB to CDM+CF via cfgrib-0....\n",
      "<xarray.Dataset>\n",
      "Dimensions:    (latitude: 81, longitude: 161, time: 731)\n",
      "Coordinates:\n",
      "  * time       (time) datetime64[ns] 2007-08-01 2007-08-01T01:00:00 ...\n",
      "  * latitude   (latitude) float64 30.0 30.25 30.5 30.75 31.0 31.25 31.5 ...\n",
      "  * longitude  (longitude) float64 -15.0 -14.75 -14.5 -14.25 -14.0 -13.75 ...\n",
      "Data variables:\n",
      "    tcc        (time, latitude, longitude) float64 ...\n",
      "    nr_nans    (time, latitude, longitude) float64 ...\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(datasets[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = xr.merge(datasets, 'equals')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:        (latitude: 81, longitude: 161, time: 744)\n",
       "Coordinates:\n",
       "  * latitude       (latitude) float64 30.0 30.25 30.5 30.75 31.0 31.25 31.5 ...\n",
       "  * time           (time) datetime64[ns] 2007-08-01 2007-08-01T01:00:00 ...\n",
       "    number         int64 0\n",
       "    step           timedelta64[ns] 00:00:00\n",
       "    isobaricInhPa  int64 1000\n",
       "  * longitude      (longitude) float64 -15.0 -14.75 -14.5 -14.25 -14.0 ...\n",
       "    valid_time     (time) datetime64[ns] 2007-08-01 2007-08-01T01:00:00 ...\n",
       "    surface        int64 0\n",
       "Data variables:\n",
       "    r              (time, latitude, longitude) float32 ...\n",
       "    t2m            (time, latitude, longitude) float32 ...\n",
       "    q              (time, latitude, longitude) float32 ...\n",
       "    sp             (time, latitude, longitude) float32 ...\n",
       "    tcc            (time, latitude, longitude) float64 0.0 0.0 0.0 0.0 0.0 ...\n",
       "    nr_nans        (time, latitude, longitude) float64 0.0 0.0 0.0 0.0 0.0 ..."
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped = data.dropna(dim='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
